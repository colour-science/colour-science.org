<!DOCTYPE html>
<html prefix="og: http://ogp.me/ns# article: http://ogp.me/ns/article#
" lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1">
<title>Physical Lighting Quantities: Tying Both Ends | Colour Science</title>
<link href="../../assets/css/colour-science.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/baguetteBox.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/rst.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/code.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/theme.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/ipython.min.css" rel="stylesheet" type="text/css">
<link href="../../assets/css/nikola_ipython.css" rel="stylesheet" type="text/css">
<meta name="theme-color" content="#191919">
<meta name="generator" content="Nikola (getnikola.com)">
<link rel="alternate" type="application/rss+xml" title="RSS" href="../../rss.xml">
<link rel="canonical" href="https://www.colour-science.org/posts/physical-lighting-quantities-tying-both-ends/">
<!--[if lt IE 9]><script src="../../assets/js/html5.js"></script><![endif]--><script src="https://code.jquery.com/jquery-3.3.1.min.js" integrity="sha256-FgpCb/KJQlLNfOu91ta32o/NMZxltwRo8QtmkMRdAu8=" crossorigin="anonymous">
</script><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.0.13/css/all.css" integrity="sha384-DNOHZ68U8hZfKXOrtjWvjxusGo9WQnrNx2sqG0tfsghAvtVlRW3tvkXWZh58N9jp" crossorigin="anonymous">
<meta name="google-site-verification" content="CeWflIcbu-x7Ur7qbzTYJiRFvoGF5RljJyGZMg7H9co">
<meta name="author" content="Colour Developers">
<link rel="prev" href="../colour-0315-is-available/" title="Colour 0.3.15 is available!" type="text/html">
<link rel="next" href="../our-first-1000-stars-on-github/" title="Our First 1000 Stars on Github!" type="text/html">
<meta property="og:site_name" content="Colour Science">
<meta property="og:title" content="Physical Lighting Quantities: Tying Both Ends">
<meta property="og:url" content="https://www.colour-science.org/posts/physical-lighting-quantities-tying-both-ends/">
<meta property="og:description" content="Validation against ground truth data is an important step when implementing
support for physical lighting quantities in a realtime or offline renderer.
In this post, a simple but effective method to a">
<meta property="og:type" content="article">
<meta property="article:published_time" content="2020-04-01T07:28:05Z">
<meta property="article:tag" content="absolute luminance calibration">
<meta property="article:tag" content="colour science">
<meta property="article:tag" content="digital still camera exposure model">
<meta property="article:tag" content="physical quantities">
</head>
<body>
<a href="#content" class="sr-only sr-only-focusable">Skip to main content</a>

<!-- Menubar -->

<nav class="navbar navbar-expand-xl static-top mb-4
navbar-dark bg-dark bg-primary
"><div class="container">
<!-- This keeps the margins nice -->
        <a class="navbar-brand" href="https://www.colour-science.org/">

            <span id="blog-title">Colour Science</span>
        </a>
        <button class="navbar-toggler" type="button" data-toggle="collapse" data-target="#bs-navbar" aria-controls="bs-navbar" aria-expanded="false" aria-label="Toggle navigation">
            <span class="navbar-toggler-icon"></span>
        </button>

        <div class="collapse navbar-collapse" id="bs-navbar">
            <ul class="navbar-nav mr-auto">
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Projects</a>
            <div class="dropdown-menu">
                    <a href="../../apps" class="dropdown-item"><span class="font-weight-bold">Apps (Colour - Dash)</span></a>
                    <a href="http://awesome-colour.org/" class="dropdown-item"><span class="font-weight-bold">Awesome Colour</span></a>
                    <a href="../../colour" class="dropdown-item"><span class="font-weight-bold">Colour</span></a>
                    <a href="../../colour-datasets" class="dropdown-item"><span class="font-weight-bold">Colour - Datasets</span></a>
                    <a href="../../colour-demosaicing" class="dropdown-item"><span class="font-weight-bold">Colour - Demosaicing</span></a>
                    <a href="../../colour-hdri" class="dropdown-item"><span class="font-weight-bold">Colour - HDRI</span></a>
                    <a href="../../colour-checker-detection" class="dropdown-item"><span class="font-weight-bold">Colour - Checker Detection</span></a>
                    <a href="../../colour-maya" class="dropdown-item">Colour - Maya</a>
                    <a href="../../colour-nuke" class="dropdown-item">Colour - Nuke</a>
                    <a href="../../colour-playground" class="dropdown-item">Colour - Playground</a>
                    <a href="../../colour-spectroscope" class="dropdown-item">Colour - Spectroscope</a>
                    <a href="../../experiments" class="dropdown-item">Experiments</a>
            </div>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Documentation</a>
            <div class="dropdown-menu">
                    <a href="../../installation-guide" class="dropdown-item"><span class="font-weight-bold">Installation Guide</span></a>
                    <a href="https://colour.readthedocs.io/en/develop/tutorial.html" class="dropdown-item"><span class="font-weight-bold">Static Tutorial</span></a>
                    <a href="https://colab.research.google.com/notebook#fileId=1Im9J7or9qyClQCv5sPHmKdyiQbG4898K&amp;offline=true&amp;sandboxMode=true" class="dropdown-item"><span class="font-weight-bold">Interactive Tutorial</span></a>
                    <a href="https://colab.research.google.com/notebook#fileId=1NRcdXSCshivkwoU2nieCvC3y14fx1X4X&amp;offline=true&amp;sandboxMode=true" class="dropdown-item"><span class="font-weight-bold">How-To Guide</span></a>
                    <a href="../../api-reference" class="dropdown-item"><span class="font-weight-bold">API Reference</span></a>
                    <a href="../../code-of-conduct" class="dropdown-item"><span class="font-weight-bold">Code of Conduct</span></a>
                    <a href="../../contributing" class="dropdown-item"><span class="font-weight-bold">Contributing</span></a>
                    <a href="../../contributors" class="dropdown-item"><span class="font-weight-bold">Contributors</span></a>
                    <a href="../../features" class="dropdown-item">Features</a>
                    <a href="../../history" class="dropdown-item">History</a>
                    <a href="https://colour.readthedocs.io/en/develop/bibliography.html" class="dropdown-item">Bibliography</a>
                    <a href="https://doi.org/10.5281/zenodo.8284953" class="dropdown-item">Cite Us</a>
                    <a href="../../cited-by" class="dropdown-item">Cited By</a>
                    <a href="https://opensource.org/licenses/BSD-3-Clause" class="dropdown-item">License</a>
                    <a href="../../search" class="dropdown-item">Search</a>
            </div>
            </li>
<li class="nav-item dropdown">
<a href="#" class="nav-link dropdown-toggle" data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">Blog</a>
            <div class="dropdown-menu">
                    <a href="../../blog" class="dropdown-item"><span class="font-weight-bold">Posts</span></a>
                    <a href="../../archive.html" class="dropdown-item">Archive</a>
                    <a href="../../categories/" class="dropdown-item">Tags</a>
            </div>
                </li>
<li class="nav-item">
<a href="mailto:colour-developers@colour-science.org" class="nav-link"><i class="fas fa-envelope"></i></a>
                </li>
<li class="nav-item">
<a href="https://github.com/colour-science/colour" class="nav-link"><i class="fab fa-github"></i></a>
                </li>
<li class="nav-item">
<a href="https://www.facebook.com/python.colour.science" class="nav-link"><i class="fab fa-facebook"></i></a>
                </li>
<li class="nav-item">
<a href="https://gitter.im/colour-science/colour" class="nav-link"><i class="fab fa-gitter"></i></a>
                </li>
<li class="nav-item">
<a href="https://twitter.com/colour_science" class="nav-link"><i class="fab fa-twitter"></i></a>

                
            </li>
</ul>
<ul class="navbar-nav navbar-right"></ul>
</div>
<!-- /.navbar-collapse -->
    </div>
<!-- /.container -->
</nav><!-- End of Menubar --><!-- Main --><div class="container" id="content" role="main">
    <div class="row">
        <div class="col-12">
            <div class="body-content">
                <!--Body content-->
                
                
                
<article class="post-text h-entry hentry postpage" itemscope="itemscope" itemtype="http://schema.org/Article"><header><h1 class="p-name entry-title" itemprop="headline name"><a href="." class="u-url">Physical Lighting Quantities: Tying Both Ends</a></h1>

        <div class="metadata">
            <p class="byline author vcard p-author h-card"><span class="byline-name fn p-name" itemprop="author">
                    Colour Developers
            </span></p>
            <p class="dateline">
            <a href="." rel="bookmark">
            <time class="published dt-published" datetime="2020-04-01T07:28:05Z" itemprop="datePublished" title="2020-04-01 07:28">2020-04-01 07:28</time></a>
            </p>
                <p class="commentline">
    
    <a href="#disqus_thread" data-disqus-identifier="cache/posts/physical-lighting-quantities-tying-both-ends.html">Comments</a>


            

        </p>
</div>
        

    </header><div class="e-content entry-content" itemprop="articleBody text">
    <p>Validation against ground truth data is an important step when implementing
support for physical lighting quantities in a realtime or offline renderer.</p>
<p>In this post, a simple but effective method to assess that the physical camera
model behaves as expected against ground truth data (or conversely) will be
presented.</p>
<!-- TEASER_END -->
<section id="digital-still-camera-exposure-model"><h2>Digital Still Camera Exposure Model</h2>
<p><a class="reference external" href="https://www.epicgames.com/site/en-US/about">Epic Games</a> recently published
a <a class="reference external" href="https://www.unrealengine.com/en-US/tech-blog/how-epic-games-is-handling-auto-exposure-in-4-25">comprehensive blog post</a>
about auto-exposure handling in Unreal Engine 4.25. The part of most significance
for this post is the mention of
<a class="reference external" href="https://www.iso.org/standard/73758.html">ISO Standard: 12232:2019</a>.</p>
<div class="alert alert-dismissible alert-info line-block">
<div class="line"><strong>Note</strong></div>
<div class="line"><br></div>
<div class="line">It is unfortunate that no reference is made to
<a class="reference external" href="https://seblagarde.files.wordpress.com/2015/07/course_notes_moving_frostbite_to_pbr_v32.pdf">Moving Frostbite to Physically Based Rendering 3.0</a>
by Lagarde and de Rousiers (2013). 7 years ago, they analytically
derived the 1.2 scaling factor while citing the aforementioned ISO
Standard: 12232:2006. They describe a plausible Digital Still Camera
(DSC) Exposure Model based on the Saturation-Based Speed (SBS) method.</div>
</div>
<p>The saturation based speed <span class="math">\(S_{sat}\)</span> of an electronic still picture
camera as given in ISO Standard: 12232:2019 is defined as:</p>
<blockquote>
<p><span class="math">\(S_{sat}=\cfrac{78}{H_{sat}}\)</span></p>
</blockquote>
<p>where <span class="math">\(H_{sat}\)</span> is the minimum focal plane exposure, expressed in
lux-seconds (<span class="math">\(lx.s\)</span>), that produces the maximum valid (not clipped or
bloomed) camera output signal. This provides <span class="math">\(1/2\)</span> "stop" of headroom
(41% additional headroom) for specular highlights above the signal level that
would be obtained from a theoretical 100% reflectance object in the scene,
so that a theoretical 141% reflectance object in the scene would produce a
focal plane exposure of <span class="math">\(H_{sat}\)</span>.</p>
<p>The focal plane exposure <span class="math">\(H\)</span> in lux-seconds is given by the following
equation:</p>
<blockquote>
<p><span class="math">\(H=\cfrac{q L t F^2}{A^2 i^2} + H_f\)</span></p>
</blockquote>
<p>where</p>
<ul>
<li><p><span class="math">\(L\)</span> is the scene luminance expressed in <span class="math">\(cd/m^2\)</span></p></li>
<li><p><span class="math">\(A\)</span> is the lens F-Number</p></li>
<li><p><span class="math">\(t\)</span> is the exposure time expressed in seconds</p></li>
<li><p><span class="math">\(F\)</span> is the lens focal length expressed in meters</p></li>
<li><p><span class="math">\(I\)</span> is the image distance expressed in meters</p></li>
<li><p><span class="math">\(H_f\)</span> is the focal plane flare exposure expressed in lux-seconds</p></li>
<li>
<p><span class="math">\(q\)</span> is the factor modeling the total lens vignetting and transmission
attenuation:</p>
<p><span class="math">\(q=\cfrac{\pi T f_v \cos^4\theta}{4}\)</span></p>
<p>with <span class="math">\(T\)</span> the transmission factor of the lens, <span class="math">\(f_v\)</span> the
vignetting factor and <span class="math">\(theta\)</span> the angle of image point off axis.
For a camera focused on infinity, <span class="math">\(Hf&lt;&lt;H\)</span>, <span class="math">\(T=9/10\)</span>,
<span class="math">\(\theta=10^{\circ}\)</span>, <span class="math">\(\cos^4\theta=94/100\)</span>, and
<span class="math">\(fv=98/100\)</span>, <span class="math">\(q\)</span> is equal to 65/100.</p>
</li>
</ul>
<div class="alert alert-dismissible alert-info line-block">
<div class="line"><strong>Note</strong></div>
<div class="line"><br></div>
<div class="line">
<a class="reference external" href="http://dougkerr.net">Doug A. Kerr</a> hosts a
<a class="reference external" href="http://dougkerr.net/Pumpkin/index.htm">series of articles</a> on
photography and optics. The following article are of interest for the
discussed topic: <a class="reference external" href="http://dougkerr.net/Pumpkin/articles/Scene_Reflectance.pdf">Average Scene Reflectance in Photographic Exposure Metering</a>
and <a class="reference external" href="http://dougkerr.net/Pumpkin/articles/Cosine_Fourth_Falloff.pdf">Derivation of the "Cosine Fourth" Law for Falloff of Illuminance Across a Camera Image</a>
</div>
</div>
<p>The adjusted focal plane exposure <span class="math">\(H_{SBS}\)</span> is obtained by scaling
the focal plane exposure <span class="math">\(H\)</span> according to the SBS method and, optionally,
scaling by the ISO arithmetic speed <span class="math">\(S\)</span>:</p>
<blockquote>
<p><span class="math">\(H_{SBS}=H\cfrac{S}{100}\cfrac{100}{78}=H\cfrac{S}{78}\)</span></p>
</blockquote>
<p><a class="reference external" href="https://github.com/colour-science/colour-hdri/blob/develop/colour_hdri/exposure/dsc.py">Colour - HDRI</a>
implements the aforementioned model with Python:</p>
<div class="code"><pre class="code python"><a id="rest_code_c12ef6f4739947a58e73ee8f332a34bc-1" name="rest_code_c12ef6f4739947a58e73ee8f332a34bc-1" href="#rest_code_c12ef6f4739947a58e73ee8f332a34bc-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">colour_hdri</span>
<a id="rest_code_c12ef6f4739947a58e73ee8f332a34bc-2" name="rest_code_c12ef6f4739947a58e73ee8f332a34bc-2" href="#rest_code_c12ef6f4739947a58e73ee8f332a34bc-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">colour_hdri</span><span class="o">.</span><span class="n">saturation_based_speed_focal_plane_exposure</span><span class="p">(</span><span class="mi">18</span><span class="p">,</span> <span class="mf">5.6</span><span class="p">,</span> <span class="mf">0.25</span><span class="p">,</span> <span class="mi">400</span><span class="p">)</span>
<a id="rest_code_c12ef6f4739947a58e73ee8f332a34bc-3" name="rest_code_c12ef6f4739947a58e73ee8f332a34bc-3" href="#rest_code_c12ef6f4739947a58e73ee8f332a34bc-3"></a><span class="mf">0.46993364546604555</span>
</pre></div>
<p><a class="reference external" href="https://github.com/colour-science/colour-nuke/blob/master/colour_nuke/scripts/digital_still_camera_exposure.nk">Colour - Nuke</a>
offers a Gizmo/Group implementation also available on
<a class="reference external" href="http://www.nukepedia.com/gizmos/image/digital_still_camera_exposure">Nukepedia</a>.</p>
<img alt="/images/Blog_Saturation_Based_Speed_Focal_Plane_Exposure_in_Nuke.png" src="../../images/Blog_Saturation_Based_Speed_Focal_Plane_Exposure_in_Nuke.png"></section><section id="panoramic-hdri-calibration"><h2>Panoramic HDRI Calibration</h2>
<p>With a plausible DSC Exposure Model implemented, calibrated ground truth data
can be imaged for verification purposes.</p>
<p><a class="reference external" href="http://blog.selfshadow.com/publications/s2016-shading-course/unity/s2016_pbs_unity_hdri_notes.pdf">An Artist-Friendly Workflow for Panoramic HDRI</a>
by Lagarde, Lachambre and Jover (2016) describes a simple but effective process
to calibrate a panoramic HDRI for absolute luminance. The only requirement is
to measure the scene illuminance with a light meter during the HDRI capture.</p>
<p>The major advantage of this approach is that it is independent of the imaging
device and thus does not require knowledge of its calibration constant <span class="math">\(K\)</span>.</p>
<p>The multiplying factor <span class="math">\(S_L\)</span> used to convert the panoramic HDRI relative
luminance values to absolute luminance values is obtained as follows:</p>
<blockquote>
<p><span class="math">\(S_L=\cfrac{E_{vm}}{E_{vi}}\)</span></p>
</blockquote>
<p>where <span class="math">\(E_{vm}\)</span> is the metered scene upper hemisphere illuminance in
lux (<span class="math">\(lx\)</span>) and <span class="math">\(E_{vi}\)</span> is the upper hemisphere illuminance of the
panoramic HDRI in lux, i.e. the upper hemisphere integral of the relative
luminance values:</p>
<blockquote>
<p><span class="math">\(\int_{\Omega}{L\ cos(\theta)\omega}\)</span></p>
</blockquote>
<p>For an equirectangular image, the solid angle <span class="math">\(\omega\)</span> of a pixel is given
as follows:</p>
<blockquote>
<p><span class="math">\(\omega=sin(\theta)\cfrac{2\pi}{w}\cfrac{\pi}{h}\)</span></p>
</blockquote>
<p>where <span class="math">\(w\)</span> and <span class="math">\(h\)</span> are the width and height of the image,
respectively.</p>
<p><a class="reference external" href="https://github.com/colour-science/colour-hdri/blob/develop/colour_hdri/calibration/absolute_luminance.py">Colour - HDRI</a>
implements support for absolute luminance calibration with Python:</p>
<div class="code"><pre class="code python"><a id="rest_code_f0ec1a914da24469b985c3dd9bb04150-1" name="rest_code_f0ec1a914da24469b985c3dd9bb04150-1" href="#rest_code_f0ec1a914da24469b985c3dd9bb04150-1"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">colour_hdri</span>
<a id="rest_code_f0ec1a914da24469b985c3dd9bb04150-2" name="rest_code_f0ec1a914da24469b985c3dd9bb04150-2" href="#rest_code_f0ec1a914da24469b985c3dd9bb04150-2"></a><span class="o">&gt;&gt;&gt;</span> <span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<a id="rest_code_f0ec1a914da24469b985c3dd9bb04150-3" name="rest_code_f0ec1a914da24469b985c3dd9bb04150-3" href="#rest_code_f0ec1a914da24469b985c3dd9bb04150-3"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">RGB</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">([</span><span class="mi">2048</span><span class="p">,</span> <span class="mi">1024</span><span class="p">,</span> <span class="mi">3</span><span class="p">])</span>
<a id="rest_code_f0ec1a914da24469b985c3dd9bb04150-4" name="rest_code_f0ec1a914da24469b985c3dd9bb04150-4" href="#rest_code_f0ec1a914da24469b985c3dd9bb04150-4"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">colour_hdri</span><span class="o">.</span><span class="n">upper_hemisphere_illuminance_Lagarde2016</span><span class="p">(</span><span class="n">RGB</span><span class="p">)</span>
<a id="rest_code_f0ec1a914da24469b985c3dd9bb04150-5" name="rest_code_f0ec1a914da24469b985c3dd9bb04150-5" href="#rest_code_f0ec1a914da24469b985c3dd9bb04150-5"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">colour_hdri</span><span class="o">.</span><span class="n">absolute_luminance_calibration_Lagarde2016</span><span class="p">(</span><span class="n">RGB</span><span class="p">,</span> <span class="mi">120000</span><span class="p">)[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">]</span>
<a id="rest_code_f0ec1a914da24469b985c3dd9bb04150-6" name="rest_code_f0ec1a914da24469b985c3dd9bb04150-6" href="#rest_code_f0ec1a914da24469b985c3dd9bb04150-6"></a><span class="n">array</span><span class="p">([</span> <span class="mf">38215.85392444</span><span class="p">,</span>  <span class="mf">38215.85392444</span><span class="p">,</span>  <span class="mf">38215.85392444</span><span class="p">])</span>
<a id="rest_code_f0ec1a914da24469b985c3dd9bb04150-7" name="rest_code_f0ec1a914da24469b985c3dd9bb04150-7" href="#rest_code_f0ec1a914da24469b985c3dd9bb04150-7"></a><span class="o">&gt;&gt;&gt;</span> <span class="n">colour_hdri</span><span class="o">.</span><span class="n">calibration</span><span class="o">.</span><span class="n">absolute_luminance</span><span class="o">.</span><span class="n">upper_hemisphere_illuminance_Lagarde2016</span><span class="p">(</span><span class="n">RGB</span><span class="p">)</span>
<a id="rest_code_f0ec1a914da24469b985c3dd9bb04150-8" name="rest_code_f0ec1a914da24469b985c3dd9bb04150-8" href="#rest_code_f0ec1a914da24469b985c3dd9bb04150-8"></a><span class="mf">3.1400580564615663</span>
</pre></div>
<div class="alert alert-dismissible alert-info line-block">
<div class="line"><strong>Note</strong></div>
<div class="line"><br></div>
<div class="line">Careful readers will have noticed that the last call to the
<cite>colour_hdri.calibration.absolute_luminance.upper_hemisphere_illuminance_Lagarde2016</cite>
definition does not return <span class="math">\(\pi\)</span>. This is induced by the
numerical discretization to raster space, however, as image dimensions
increase toward infinity, the computed value converges toward
<span class="math">\(\pi\)</span>, e.g. 3.1414009 and 3.1414968 for 16384x8192 and 32768x16384
sized images respectively.</div>
</div>
<p>Likewise, <a class="reference external" href="https://github.com/colour-science/colour-nuke/blob/master/colour_nuke/scripts/panoramic_hdri_absolute_luminance_calibration.nk">Colour - Nuke</a>
offers a Gizmo/Group implementation also available on
<a class="reference external" href="http://www.nukepedia.com/gizmos/colour/panoramic-hdri-absolute-luminance-calibration">Nukepedia</a>.</p>
<img alt="/images/Blog_Absolute_Luminance_Calibration_in_Nuke.png" src="../../images/Blog_Absolute_Luminance_Calibration_in_Nuke.png"></section><section id="imaging-the-panoramic-hdri-with-the-digital-still-camera-exposure-model"><h2>Imaging the Panoramic HDRI with the Digital Still Camera Exposure Model</h2>
<p>A free panoramic HDRI processed accurately is a rarity online. Most vendors
sell either non-linear or clipped imagery, and when it is not clipped,
photometric and colorimetric information is missing and because the creation
process is unknown, the data cannot be trusted for scientific applications
requiring physical lighting quantities.</p>
<p>Fortunately, Lagarde, Lachambre and Jover (2016) have published <a class="reference external" href="https://blog.selfshadow.com/publications/s2016-shading-course/unity/supplemental/index.html">a trustworthy
panoramic HDRI</a>
that will be used in this section.</p>
<figure><img alt="/images/Blog_Unity_Treasure_Island_ReStitched.png" src="../../images/Blog_Unity_Treasure_Island_ReStitched.png"><figcaption><p>Final Treasure Island panoramic HDRI merged and stitched from the original
.CR2 files.</p>
</figcaption></figure><p>The authors have been kindly enough to send me the original .CR2 files so that
I could merge and stitch them.</p>
<p>Merging was performed with <a class="reference external" href="https://github.com/colour-science/colour-hdri/blob/develop/colour_hdri/generation/radiance.py">Colour - HDRI</a>,
specifically, by using a modified version of the
<a class="reference external" href="https://github.com/colour-science/colour-hdri/blob/develop/colour_hdri/examples/examples_merge_from_raw_files.ipynb">Merge from Raw Files</a>
example.</p>
<div class="alert alert-dismissible alert-warning line-block">
<div class="line"><strong>Warning</strong></div>
<div class="line"><br></div>
<div class="line">The aforementioned Jupyter Notebook is an example, typical production
usage would require multi-processing and use
<a class="reference external" href="https://pypi.org/project/rawpy">rawpy</a> or
<a class="reference external" href="https://github.com/ampas/rawtoaces">rawtoaces</a>.</div>
</div>
<figure><img alt="/images/Blog_Unity_Treasure_Island_ReStitched_Angles.png" src="../../images/Blog_Unity_Treasure_Island_ReStitched_Angles.png"><figcaption><p>.CR2 file batches merged to HDRI. Note that the bottom row was captured
with neutral density filters.</p>
</figcaption></figure><p>With the various .CR2 file batches merged, the validation process involves
comparing a cherry picked .CR2 file from one of the exposure batches with the
corresponding HDRI scaled to absolute luminance and imaged via the DSC Exposure
Model using the camera settings of the .CR2 file.</p>
<figure><img alt="/images/Blog_Unity_Treasure_Island_Angle_Imaged.png" src="../../images/Blog_Unity_Treasure_Island_Angle_Imaged.png"><figcaption><p>From left to right: The HDRI scaled to absolute luminance using 51000 lux,
the cherry picked .CR2 file, the HDRI scaled to absolute luminance and
imaged with the DSC Exposure Model.</p>
</figcaption></figure></section><section id="conclusion"><h2>Conclusion</h2>
<p>With Treasure Island, the HDRI scaled to absolute luminance is about 14%
brighter (clipped luminance) than the .CR2 file. This is not perfect but
considering the scaling factors involved, it is reasonably satisfactory.</p>
<p>Some potential source of discrepancies are:</p>
<ul class="simple">
<li><p>Lack of flat-fields to correct the neutral density filter attenuation and
thus some manual correction was introduced.</p></li>
<li><p>Illuminance measurement precision.</p></li>
<li><p>Sun pixel coverage is small and might introduce significant error.</p></li>
<li><p>Unknown parameters for the focal plane exposure equation that were left at
their default values, e.g. lens attenuation values.</p></li>
</ul>
<p>Other tests performed with various non-public HDRI but imaged similarly have
yielded better results with less error. Importantly though, the technique is
dependent on good metering of the scene upper hemisphere illuminance along with
non-clipped capture and correct processing of HDR imagery.</p>
<p>Conversely and assuming a correctly implemented (DSC) Exposure Model, this
method also allows to check if the panoramic HDRI is correctly captured and
processed.</p>
<p>Finally, I would like to thanks Sebastien Lagarde, Sebastien Lachambre and
Cyril Jover for the recurring conversations on that topic during the past few
years.</p>
</section>
</div>
    <aside class="postpromonav"><nav><ul itemprop="keywords" class="tags">
<li><a class="tag p-category" href="../../categories/absolute-luminance-calibration/" rel="tag">absolute luminance calibration</a></li>
            <li><a class="tag p-category" href="../../categories/colour-science/" rel="tag">colour science</a></li>
            <li><a class="tag p-category" href="../../categories/digital-still-camera-exposure-model/" rel="tag">digital still camera exposure model</a></li>
            <li><a class="tag p-category" href="../../categories/physical-quantities/" rel="tag">physical quantities</a></li>
        </ul>
<ul class="pager hidden-print">
<li class="previous">
                <a href="../colour-0315-is-available/" rel="prev" title="Colour 0.3.15 is available!">Previous post</a>
            </li>
            <li class="next">
                <a href="../our-first-1000-stars-on-github/" rel="next" title="Our First 1000 Stars on Github!">Next post</a>
            </li>
        </ul></nav></aside><section class="comments hidden-print"><h2>Comments</h2>
        
    
        <div id="disqus_thread"></div>
        <script>
        var disqus_shortname ="colour-science",
            disqus_url="https://www.colour-science.org/posts/physical-lighting-quantities-tying-both-ends/",
        disqus_title="Physical Lighting Quantities: Tying Both Ends",
        disqus_identifier="cache/posts/physical-lighting-quantities-tying-both-ends.html",
        disqus_config = function () {
            this.language = "en";
        };
        (function() {
            var dsq = document.createElement('script'); dsq.async = true;
            dsq.src = 'https://' + disqus_shortname + '.disqus.com/embed.js';
            (document.getElementsByTagName('head')[0] || document.getElementsByTagName('body')[0]).appendChild(dsq);
        })();
    </script><noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript" rel="nofollow">comments powered by Disqus.</a>
</noscript>
    <a href="https://disqus.com" class="dsq-brlink" rel="nofollow">Comments powered by <span class="logo-disqus">Disqus</span></a>


        </section><script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML" integrity="sha384-3lJUsx1TJHt7BA4udB5KPnDrlkO8T6J6v/op7ui0BbCjvZ9WqV4Xm6DTP6kQ/iBH" crossorigin="anonymous"></script><script type="text/x-mathjax-config">
        MathJax.Hub.Config({tex2jax: {inlineMath: [['$latex ','$'], ['\\(','\\)']]}});
        </script></article><script>var disqus_shortname="colour-science";(function(){var a=document.createElement("script");a.async=true;a.src="https://"+disqus_shortname+".disqus.com/count.js";(document.getElementsByTagName("head")[0]||document.getElementsByTagName("body")[0]).appendChild(a)}());</script><!--End of body content-->
</div>
        </div>
    </div>
</div>

<!-- End of Main -->

<!-- Footer -->

<footer id="footer" class="mt-auto"><ul class="nav justify-content-center">
<li class="nav-item mx-3">
        <a href="mailto:colour-developers@colour-science.org">
            <i class="fas fa-envelope text-light"></i>
        </a>
    </li>
    <li class="nav-item mx-3">
        <a href="https://github.com/colour-science/colour">
            <i class="fab fa-github text-light"></i>
        </a>
    </li>
    <li class="nav-item mx-3">
        <a href="https://gitter.im/colour-science/colour">
            <i class="fab fa-gitter text-light"></i>
        </a>
    </li>
    <li class="nav-item mx-3">
        <a href="https://twitter.com/colour_science">
            <i class="fab fa-twitter text-light"></i>
        </a>
    </li>
    <li class="nav-item mx-3">
        <a href="https://www.facebook.com/python.colour.science">
            <i class="fab fa-facebook text-light"></i>
        </a>
    </li>
</ul>
<div class="text-center text-light py-3"><span>Copyright © 2013-2023 – Colour Developers</span></div>

    
</footer><!-- End of Footer --><script src="../../assets/js/jquery.min.js"></script><script src="../../assets/js/popper.min.js"></script><script src="../../assets/js/bootstrap.min.js"></script><script src="../../assets/js/baguetteBox.min.js"></script><script>
    baguetteBox.run('div#content', {
        ignoreClass: 'islink',
        captions: function(element) {
            return element.getElementsByTagName('img')[0].alt;
    }});
    </script><!-- >>> Gitter --><script>
  ((window.gitter = {}).chat = {}).options = {
    room: 'colour-science/colour'
  };
</script><script async src="https://sidecar.gitter.im/dist/sidecar.v1.js"></script><!-- <<< Gitter --><!-- >>> Google Analytics --><script async src="https://www.colour-science.org/assets/js/analytics.js"></script><!-- <<< Google Analytics -->
</body>
</html>
